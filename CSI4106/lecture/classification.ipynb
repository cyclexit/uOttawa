{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    71\n",
      "0    59\n",
      "2    48\n",
      "Name: target, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   alcohol                       178 non-null    float64\n",
      " 1   malic_acid                    178 non-null    float64\n",
      " 2   ash                           178 non-null    float64\n",
      " 3   alcalinity_of_ash             178 non-null    float64\n",
      " 4   magnesium                     178 non-null    float64\n",
      " 5   total_phenols                 178 non-null    float64\n",
      " 6   flavanoids                    178 non-null    float64\n",
      " 7   nonflavanoid_phenols          178 non-null    float64\n",
      " 8   proanthocyanins               178 non-null    float64\n",
      " 9   color_intensity               178 non-null    float64\n",
      " 10  hue                           178 non-null    float64\n",
      " 11  od280/od315_of_diluted_wines  178 non-null    float64\n",
      " 12  proline                       178 non-null    float64\n",
      " 13  target                        178 non-null    int64  \n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 19.6 KB\n",
      "None\n",
      "(178, 14)\n"
     ]
    }
   ],
   "source": [
    "wine = datasets.load_wine(as_frame=True)\n",
    "df_wine_data = wine['data']\n",
    "labels = wine['target']\n",
    "df = pd.concat([df_wine_data, labels], axis=1)\n",
    "print(df.target.value_counts())\n",
    "print(df.info())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# check if there is any missing value\n",
    "print(df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.403226\n",
      "0    0.330645\n",
      "2    0.266129\n",
      "Name: target, dtype: float64\n",
      "1    0.388889\n",
      "0    0.333333\n",
      "2    0.277778\n",
      "Name: target, dtype: float64\n",
      "(124, 13)\n",
      "(54, 13)\n"
     ]
    }
   ],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "for train_index, test_index in split.split(df, df['target']):\n",
    "    train_set = df.loc[train_index]\n",
    "    test_set = df.loc[test_index]\n",
    "\n",
    "\n",
    "# data = df.drop(\"target\", axis=1).copy().to_numpy()\n",
    "# labels = df[\"target\"].copy().to_numpy()\n",
    "\n",
    "# train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "print(train_set.target.value_counts()/len(train_set))\n",
    "print(test_set.target.value_counts()/len(test_set))\n",
    "\n",
    "train_data = train_set.drop(\"target\", axis=1) \n",
    "train_labels = train_set[\"target\"].copy().to_numpy()\n",
    "print(train_data.shape)\n",
    "\n",
    "test_data = test_set.drop(\"target\", axis=1) \n",
    "test_labels = test_set[\"target\"].copy().to_numpy()\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# # scaler = StandardScaler()\n",
    "# train_scaled = scaler.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# NOTE: MinMaxScaler -> values are within the range 0 and 1\n",
    "# NOTE: StandardScaler -> mean of 0 and standard deviation of 1\n",
    "scaler = MinMaxScaler()\n",
    "# scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train_data.values)\n",
    "# print(scaled_features)\n",
    "# print(scaled_features.shape)\n",
    "scaled_df = pd.DataFrame(train_scaled, index=train_set.index, columns=train_data.columns)\n",
    "\n",
    "# NOTE: if Normalized, max -> 1, min -> 0\n",
    "print(np.max(scaled_df.alcohol.to_numpy()))\n",
    "print(np.min(scaled_df.alcohol.to_numpy()))\n",
    "\n",
    "# NOTE: if Standardized, mean -> 0, std -> 1\n",
    "# print(np.mean(scaled_df.alcohol.to_numpy()))\n",
    "# print(np.std(scaled_df.alcohol.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "SVC(C=10, gamma=0.001, kernel='linear', random_state=42)\n"
     ]
    }
   ],
   "source": [
    "model = SVC(random_state=42)\n",
    "# specify the parameter combinations to be tested\n",
    "parameters = [\n",
    "    {'C': [10, 100], 'gamma': [0.001, 0.0001], 'kernel': ['linear', 'rbf']}\n",
    "]\n",
    "\n",
    "# NOTE: becuase the metric has to be maximized we use \"neg_mean_squared_error\"\n",
    "grid_search = GridSearchCV(model, parameters, cv=10, return_train_score=True, n_jobs=-1)\n",
    "grid_search.fit(train_scaled, train_labels)\n",
    "\n",
    "# print the best parameters\n",
    "print(grid_search.best_params_)\n",
    "# the best estimator\n",
    "print(grid_search.best_estimator_)\n",
    "# can also get the best results for each run with different feature combinations\n",
    "cross_val_results = grid_search.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        41\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        33\n",
      "\n",
      "    accuracy                           1.00       124\n",
      "   macro avg       1.00      1.00      1.00       124\n",
      "weighted avg       1.00      1.00      1.00       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_predictions = grid_search.best_estimator_.predict(train_scaled)\n",
    "cls_report_train = classification_report(train_labels, train_predictions)\n",
    "print(cls_report_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        18\n",
      "           1       1.00      0.95      0.98        21\n",
      "           2       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.98      0.98      0.98        54\n",
      "weighted avg       0.98      0.98      0.98        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_scaled = scaler.transform(test_data.values)\n",
    "test_predictions = grid_search.best_estimator_.predict(test_scaled)\n",
    "cls_report_test = classification_report(test_labels, test_predictions)\n",
    "print(cls_report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_scaled = scaler.transform(test_data)\n",
    "# test_predictions = grid_search.best_estimator_.predict(test_scaled)\n",
    "# cls_report_test = classification_report(test_labels, test_predictions)\n",
    "# print(cls_report_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcacb1169d0317e97b762e0c1a317633c556cb59cb1017287d7e24b96b766e04"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('csi4106': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
